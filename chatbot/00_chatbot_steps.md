# Chatbot 搭建的整体逻辑

- 确定聊天需求与场景
  - 目标：明确聊天机器人的主要功能与服务对象，如普通问答、领域问答（金融、医疗）或者闲聊对话等。
  - 输出风格：需要怎样的回复风格（简洁、幽默、专业）？
- 选择并加载 LLM
  - 确定使用的 LLM 模型（规模、开源/商用）
  - 准备相应的依赖库（如 transformers, langchain 等）
- 设计 Prompt（提示词）
  - Prompt 的内容和形式决定了回复的质量与方向
  - 基础方法：拼接用户输入 + 系统指令，形成合适的上下文
  - 进阶方法：提示工程（Prompt Engineering），通过模板或引导语控制模型输出
- 搭建交互接口
  - 输入：用户问题（自然语言）
  - 预处理：根据需求进行文本清洗、过滤敏感词等
  - 推理：将用户输入拼接到 Prompt，送入 LLM 生成回复
  - 后处理：对生成的文本进行修饰、截断、过滤，最终返回给用户
- 维护对话状态（多轮对话）
  - 上下文管理：保留前几轮问答内容
  - 对话历史：存储最近几条交流，避免 LLM“健忘”
  - 缓存策略：对于用户常见的问题可进行缓存或检索
- 部署与优化
  - 部署方式：本地部署（GPU/CPU）或云端推理（GPU/TPU）
  - 优化：
    - 微调（Fine-tuning 或 LoRA）
    - 模型压缩、量化（8-bit/4-bit）
    - 分批推理或流水线并行提高速度
- 监控与迭代
  - 收集用户反馈，查看回答的准确性、连贯性、错误率等
  - 不断调整 Prompt、模型参数、或考虑更大规模的模型

# 可选的开源 LLM 模型

- GPT-2
  - 规模：1.5 亿参数（GPT-2 large）及其他更小/更大的变体
  - 优点：模型轻量、资源消耗较低，容易本地部署
  - 缺点：生成质量较新一代模型略显不足，理解长上下文能力有限
- GPT-J (6B)
  - 规模：60 亿参数
  - 优点：Open Source 模型，生成效果比 GPT-2 更好
  - 缺点：部署需要一定的 GPU 资源，推理速度比小模型更慢
- GPT-Neo/GPT-NeoX
  - GPT-Neo (1.3B/2.7B) 和 GPT-NeoX (20B)
  - 优点：同样是 EleutherAI 开源，规模可选，支持多种场景
  - 缺点：参数较多（如 20B），本地部署的硬件要求较高
- Llama 2 系列
  - 规模：7B、13B、70B 等
  - 优点：Meta 提供的开源模型，性能优异；7B/13B 规模相对容易部署
  - 缺点：使用和发布需要遵从 Meta 开源协议，仍需 GPU (>=24GB) 才能流畅推理
- Mistral 系列
  - 新一代小而精的开源模型，如 Mistral-7B
  - 优点：比同参数规模的模型更快、更准确，易于部署
  - 缺点：生态可能还在成长阶段，社区支持和资料相对少一些
- Falcon 系列
  - Falcon-7B、Falcon-40B
  - 优点：在开源模型排行榜中性能突出
  - 缺点：规模较大，GPU 显存需求较高

在构建简易 Chatbot 时，更推荐使用 7B~13B 参数级别的模型，例如 Llama 2-7B 或 Mistral-7B 等，在性能和资源消耗之间取得平衡。若设备资源不足，可选择 GPT-2 或 GPT-Neo 2.7B 作为过渡。
